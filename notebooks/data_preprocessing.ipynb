{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd644883",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "In this notebook, we load and preprocess a labeled dataset of news articles for training a fake news classification model.  \n",
    "We'll clean, label, shuffle, and split the dataset into training, validation, and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a006c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075c3869",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "\n",
    "We are using the **ISOT Fake News Dataset**, which contains two CSV files:\n",
    "\n",
    "- `isot_Fake.csv` → Contains fake news articles\n",
    "- `isot_True.csv` → Contains real news articles\n",
    "\n",
    "We'll load each into a DataFrame using pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4b73d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df = pd.read_csv('../data/isot_Fake.csv')\n",
    "real_df = pd.read_csv('../data/isot_True.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184a15a3",
   "metadata": {},
   "source": [
    "## Label the Data\n",
    "\n",
    "To train a binary classifier, we need to label the articles:\n",
    "- Fake news → `label = 0`\n",
    "- Real news → `label = 1`\n",
    "\n",
    "We'll add a new column `label` to each DataFrame accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6647d5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df['label'] = 0\n",
    "real_df['label'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2b337a",
   "metadata": {},
   "source": [
    "## Merge and Shuffle the Dataset\n",
    "\n",
    "We'll now combine both datasets into one DataFrame using `pd.concat()`.  \n",
    "To avoid any learning bias, we will shuffle the combined dataset randomly.  \n",
    "We'll also reset the index for a clean, continuous DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8391b0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([fake_df, real_df], ignore_index = True)\n",
    "df = df.sample(frac = 1, random_state = 42).reset_index(drop =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba80ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_text'] = df['title'].fillna(' ') + ' ' + df['text'].fillna(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c98e42f",
   "metadata": {},
   "source": [
    "## Clean the Text\n",
    "\n",
    "We combine the `title` and `text` fields into a new `full_text` column.  \n",
    "This gives the model richer context when making predictions.\n",
    "\n",
    "We also define a `clean_text()` function to:\n",
    "- Lowercase the text\n",
    "- Strip whitespace\n",
    "- Remove newline characters\n",
    "\n",
    "This step improves consistency and prevents tokenization errors later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c2904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower().strip()\n",
    "    text = text.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    return text\n",
    "\n",
    "df['full_text'] = df['full_text'].apply(clean_text) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872bf6ae",
   "metadata": {},
   "source": [
    "## Keep Only Relevant Columns\n",
    "\n",
    "Now that we’ve created the `full_text`, we no longer need the original `title` or `text`.  \n",
    "We’ll keep only the `full_text` and `label` columns for simplicity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b1900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['full_text', 'label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d695d08c",
   "metadata": {},
   "source": [
    "## Split the Dataset\n",
    "\n",
    "We'll split the dataset into:\n",
    "- **80%** Training set\n",
    "- **10%** Validation set\n",
    "- **10%** Test set\n",
    "\n",
    "We use `train_test_split()` twice:\n",
    "1. First to split `train + temp`\n",
    "2. Then to split `temp` into `val` and `test`\n",
    "\n",
    "We also stratify on the `label` to preserve class balance across all splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18022a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, temp_df = train_test_split(df, test_size = 0.2, random_state = 42, stratify = df['label'])\n",
    "val_df, test_df = train_test_split(temp_df, test_size = 0.5, random_state = 42, stratify = df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5825c3",
   "metadata": {},
   "source": [
    "## Save the Preprocessed Splits\n",
    "\n",
    "Finally, we save the `train`, `val`, and `test` DataFrames to CSV files.  \n",
    "These files will be used in the next stage: **tokenization and model training**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a6c1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('../data/train.csv', index=False)\n",
    "val_df.to_csv('../data/val.csv', index=False)\n",
    "test_df.to_csv('../data/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed44ce36",
   "metadata": {},
   "source": [
    "## Preprocessing Complete\n",
    "\n",
    "- Loaded and labeled fake/real news articles\n",
    "- Combined and shuffled the data\n",
    "- Cleaned the text and merged title + body\n",
    "- Split into train, validation, and test sets\n",
    "- Saved the processed files to `data/`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
